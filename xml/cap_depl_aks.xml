<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha-cap-depl-aks"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Deploying &productname; on &aks-full; (AKS)</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <important>
     &readmefirst;
 </important>
 <para>
  &productname; supports deployment on &aks-full;
  (AKS), Microsoft's managed &kube; service. This chapter describes the steps
  for preparing Azure for a &productname; deployment, deployed with the default
  Azure Standard SKU load balancer (see
  <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/load-balancer-standard"/>).
 </para>
 <para>
  In &kube; terminology a node used to be a minion, which was the name for a
  worker node. Now the correct term is simply node (see
  <link xlink:href="https://kubernetes.io/docs/concepts/architecture/nodes/"></link>).
  This can be confusing, as computing nodes have traditionally been defined as
  any device in a network that has an IP address. In Azure they are called
  agent nodes. In this chapter we call them agent nodes or &kube; nodes.
 </para>
 <sect1 xml:id="sec-cap-prereqs-aks">
  <title>Prerequisites</title>

  <para>
   The following are required to deploy and use &productname; on AKS:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>az</command>, the Azure command line client. See
     <link xlink:href="https://docs.microsoft.com/en-us/cli/azure/?view=azure-cli-latest"/>
     for more information and installation instructions.
    </para>
   </listitem>
   <listitem>
    <para>
     A &ms; Azure account. For details, refer to
     <link xlink:href="https://azure.microsoft.com"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Your Azure account as sufficient quota. The minimal installation described
     in this chapter require 24 vCPUs. If your account has insufficient quota,
     you can request a quota increase by going to
     <link xlink:href="https://docs.microsoft.com/en-us/azure/azure-supportability/resource-manager-core-quotas-request"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     A SSH key that can be used for access to the nodes of the cluster. 
    </para>
   </listitem>

   <!-- listitems: Install steps and links -->
   &cfcli-prereq;
   &kubectl-prereq;
   &jq-prereq;
   &curl-prereq;
   &sed-prereq;
  </itemizedlist>

  &min-deploy-note;
 </sect1>
 <sect1 xml:id="sec-cap-create-aks-instance">
  <title>Create Resource Group and AKS Instance</title>

  <para>
   Log in to your Azure account, which should have the
   <literal>Contributor</literal> role.
  </para>

<screen>&prompt.user;az login</screen>

  <para>
  </para>

  <para>
   You can set up an AKS cluster with an automatically generated service
   principal. Note that to be be able to create a service principal your user
   account must have permissions to register an application with your Azure
   Active Directory tenant, and to assign the application to a role in your
   subscription. For details, see <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#automatically-create-and-use-a-service-principal"/>.
  </para>
  
  <para>
   Alternatively, you can specify an existing service principal but the service
   principal must have sufficient rights to be able to create resources at the
   appropriate level, for example resource group, subscription etc. For more
   details please see:
  </para>

  <itemizedlist>
   <listitem>
    <para>
      Create a service principal: <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#manually-create-a-service-principal"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Create a role assignment for the service principal, at the subscription or
     resource group level: <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#delegate-access-to-other-azure-resources"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Create the cluster with the service principal: <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#specify-a-service-principal-for-an-aks-cluster"/>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Specify the following additional parameters for creating the cluster: node
   count, a username for SSH access to the nodes, SSH key, VM type, VM disk size
   and optionally, the &kube; version and a nodepool name.
  </para>

<screen>&prompt.user;az aks create --resource-group <replaceable>my-resource-group</replaceable> --name <replaceable>cap-aks</replaceable> \
 --node-count <replaceable>3</replaceable> --admin-username <replaceable>cap-user</replaceable> \
 --ssh-key-value <replaceable>/path/to/some_key.pub</replaceable> --node-vm-size <replaceable>Standard_DS4_v2</replaceable> \
 --node-osdisk-size <replaceable>&node_size;</replaceable> --nodepool-name <replaceable>my-pool</replaceable>
</screen>

  <para>
   For more <command>az aks create</command> options see
   <link xlink:href="https://docs.microsoft.com/en-us/cli/azure/aks?view=azure-cli-latest#az-aks-create"/>.
  </para>

  <para>
   This takes a few minutes. When it is completed, fetch your
   <command>kubectl</command> credentials. The default behavior for <command>az
   aks get-credentials</command> is to merge the new credentials with the
   existing default configuration, and to set the new credentials as as the
   current &kube; context. The context name is your AKS_NAME value. You should
   first backup your current configuration, or move it to a different location,
   then fetch the new credentials:
  </para>

<screen>&prompt.user;az aks get-credentials --resource-group $RG_NAME --name $AKS_NAME
 Merged "cap-aks" as current context in /home/&exampleuser_plain;/.kube/config</screen>

  <para>
   Verify that you can connect to your cluster:
  </para>

<screen>&prompt.user;kubectl get nodes</screen>

  <para>
   When all nodes are in a ready state and all pods are running, proceed to the
   next steps.
  </para>
 </sect1>

  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &install-helm;

 <sect1 xml:id="sec-cap-aks-storage">
  &storage-class;
 </sect1>

 <sect1 xml:id="sec-cap-aks-config">
  <title>Deployment Configuration</title>
  <para>
   The following file, &values-filename;, provides a
   complete example deployment configuration.
  </para>

  &values-file-changes;

  &supported-domains;

<screen>
### example deployment configuration file
### &values-file;

<!-- TODO-CAP2 -->
</screen>

 </sect1>

 <!-- Begin optional features -->

 <sect1 xml:id="sec-cap-aks-certificates">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &certificates;
 </sect1>

 <sect1 xml:id="sec-cap-aks-ingress">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &ingress-controller;
 </sect1>

 <sect1 xml:id="sec-cap-aks-high-availability">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &high-availability;
 </sect1>

 <sect1 xml:id="sec-cap-aks-external-blobstore">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &external-blobstore;
 </sect1>

 <sect1 xml:id="sec-cap-aks-external-database">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &external-database;
 </sect1>

 <!-- End optional features -->

 <sect1 xml:id="sec-cap-addrepo-aks">
  <title>Add the &kube; Charts Repository</title>

  <para>
   Download the &suse; &kube; charts repository with &helm;:
  </para>

<screen>&prompt.user;helm repo add <replaceable>suse</replaceable> https://kubernetes-charts.suse.com/</screen>

  <para>
   You may replace the example <replaceable>suse</replaceable> name with any
   name. Verify with <command>helm</command>:
  </para>

<screen>&prompt.user;helm repo list
NAME       URL
stable     https://kubernetes-charts.storage.googleapis.com
local      http://127.0.0.1:8879/charts
suse       https://kubernetes-charts.suse.com/
</screen>

  <para>
   List your chart names, as you will need these for some operations:
  </para>

&helm-search-suse;

 </sect1>
 <sect1 xml:id="sec-cap-cap-on-aks">
  <title>Deploying &productname;</title>
  <para>
   This section describes how to deploy &productname; with a Azure Standard SKU
   load balancer.
  </para>

  &kubecf-operator-versions;

  <sect2 xml:id="sec-cap-aks-deploy-operator">
   &deploy-operator;
  </sect2>

  <sect2 xml:id="sec-cap-aks-deploy-kubecf">
   <title>Deploy &kubecf;</title>
   <procedure>
    &deploy-kubecf;
    <step>
     <para>
      Create DNS A records for the public services.
     </para>
     &dns-mappings;
    </step>
    <step>
     <para>
      When all pods are fully ready, verify your deployment.
     </para>
     &cf-auth;
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-cap-azure-service-broker">
  <title>Configuring and Testing the Native &aks; Service Broker</title>

  <para>
   &aks-full; provides a service broker called the Open Service Broker for
   Azure (see <link xlink:href="https://github.com/Azure/open-service-broker-azure"/>.
   This section describes how to use it with your &productname; deployment.
  </para>

  <para>
   Usage of the broker requires a cluster running &kube; 1.15 or earlier.
  </para>

  <para>
   Start by extracting and setting a batch of environment variables:
  </para>

<screen>&prompt.user;SBRG_NAME=$(tr -dc 'a-zA-Z0-9' &lt; /dev/urandom | head -c 8)-service-broker

&prompt.user;REGION=<replaceable>eastus</replaceable>

&prompt.user;export SUBSCRIPTION_ID=$(az account show | jq -r '.id')

&prompt.user;az group create --name ${SBRG_NAME} --location ${REGION}

&prompt.user;SERVICE_PRINCIPAL_INFO=$(az ad sp create-for-rbac --name ${SBRG_NAME})

&prompt.user;TENANT_ID=$(echo ${SERVICE_PRINCIPAL_INFO} | jq -r '.tenant')

&prompt.user;CLIENT_ID=$(echo ${SERVICE_PRINCIPAL_INFO} | jq -r '.appId')

&prompt.user;CLIENT_SECRET=$(echo ${SERVICE_PRINCIPAL_INFO} | jq -r '.password')

&prompt.user;echo SBRG_NAME=${SBRGNAME}

&prompt.user;echo REGION=${REGION}

&prompt.user;echo SUBSCRIPTION_ID=${SUBSCRIPTION_ID} \; TENANT_ID=${TENANT_ID}\; CLIENT_ID=${CLIENT_ID}\; CLIENT_SECRET=${CLIENT_SECRET}
</screen>

  <para>
   Add and install the catalog  &helm; chart. The CPU and memory's requests and
   limits must be increased, otherewise the installation fails due to a
   <literal>OOMKilled</literal> state. This example, increases these to double
   the default:
  </para>

<screen>&prompt.user;helm repo add svc-cat https://svc-catalog-charts.storage.googleapis.com

&prompt.user;helm repo update

&prompt.user;kubectl create namespace <replaceable>catalog</replaceable>

&prompt.user;helm install <replaceable>catalog</replaceable> svc-cat/catalog \
 --namespace catalog \
 --set controllerManager.healthcheck.enabled=false \
 --set apiserver.healthcheck.enabled=false \
 --set controllerManager.resources.requests.cpu=200m \
 --set controllerManager.resources.requests.memory=40Mi \
 --set controllerManager.resources.limits.cpu=200m \
 --set controllerManager.resources.limits.memory=40Mi

&prompt.user;kubectl get apiservice

&prompt.user;helm repo add azure https://kubernetescharts.blob.core.windows.net/azure

&prompt.user;helm repo update
</screen>

  <para>
   Set up the service broker with your variables:
  </para>

<screen>&prompt.user;kubectl create namespace <replaceable>osba</replaceable>

&prompt.user;helm install <replaceable>osba</replaceable> azure/open-service-broker-azure \
--namespace <replaceable>osba</replaceable> \
--set azure.subscriptionId=${SUBSCRIPTION_ID} \
--set azure.tenantId=${TENANT_ID} \
--set azure.clientId=${CLIENT_ID} \
--set azure.clientSecret=${CLIENT_SECRET} \
--set azure.defaultLocation=${REGION} \
--set redis.persistence.storageClass=default \
--set basicAuth.username=$(tr -dc 'a-zA-Z0-9' &lt; /dev/urandom | head -c 16) \
--set basicAuth.password=$(tr -dc 'a-zA-Z0-9' &lt; /dev/urandom | head -c 16) \
--set tls.enabled=false
</screen>
  <para>
   Monitor the progress:
  </para>
<screen>&prompt.user;watch --color 'kubectl get pods --namespace osba'</screen>
  <para>
   When all pods are running, create the service broker in &kubecf; using the &cfcli;:
  </para>
<screen>
&prompt.user;cf login

&prompt.user;cf create-service-broker <replaceable>azure</replaceable> $(kubectl get deployment osba-open-service-broker-azure \
--namespace osba --output jsonpath='{.spec.template.spec.containers[0].env[?(@.name == "BASIC_AUTH_USERNAME")].value}') $(kubectl get secret --namespace osba osba-open-service-broker-azure --output jsonpath='{.data.basic-auth-password}' | base64 --decode) http://osba-open-service-broker-azure.osba
</screen>

  <para>
   List the available service plans. For more information about the services
   supported see
   <link xlink:href="https://github.com/Azure/open-service-broker-azure#supported-services"/>:
  </para>
<screen>&prompt.user;cf service-access -b <replaceable>azure</replaceable></screen>
  <para>
   Use <command>cf enable-service-access</command> to enable access to a service plan. This
   example enables all <literal>basic</literal> plans:
  </para>
<screen>
&prompt.user;cf service-access -b <replaceable>azure</replaceable> | \
awk '($2 ~ /basic/) { system("cf enable-service-access " $1 " -p " $2)}'
</screen>

  <para>
   Test your new service broker with an example PHP application. First create an
   organization and space to deploy your test application to:
  </para>

<screen>
&prompt.user;cf create-org <replaceable>testorg</replaceable>

&prompt.user;cf create-space <replaceable>kubecftest</replaceable> -o <replaceable>testorg</replaceable>

&prompt.user;cf target -o "<replaceable>testorg</replaceable>" -s "<replaceable>kubecftest</replaceable>"

&prompt.user;cf create-service azure-mysql-5-7 basic <replaceable>question2answer-db</replaceable> \
-c "{ \"location\": \"${REGION}\", \"resourceGroup\": \"${SBRG_NAME}\", \"firewallRules\": [{\"name\": \
\"AllowAll\", \"startIPAddress\":\"0.0.0.0\",\"endIPAddress\":\"255.255.255.255\"}]}"

&prompt.user;cf service <replaceable>question2answer-db</replaceable> | grep status
</screen>

  <para>
   Find your new service and optionally disable TLS. You should not disable TLS
   on a production deployment, but it simplifies testing. The
   <literal>mysql2</literal> gem must be configured to use TLS, see
   <link xlink:href="https://github.com/brianmario/mysql2#ssl-options">brianmario/mysql2/SSL
   options</link> on GitHub:
  </para>

<screen>
&prompt.user;az mysql server list --resource-group $SBRG_NAME

&prompt.user;az mysql server update --resource-group $SBRG_NAME \
--name <replaceable>kubecftest</replaceable> --ssl-enforcement Disabled
</screen>

  <para>
   Look in your Azure portal to find your database <literal>--name</literal>.
  </para>

  <para>
   Build and push the example PHP application:
  </para>

<screen>
&prompt.user;git clone https://github.com/scf-samples/question2answer

&prompt.user;cd question2answer

&prompt.user;cf push

&prompt.user;cf service question2answer-db # => bound apps
</screen>

  <para>
   When the application has finished deploying, use your browser and
   navigate to the URL specified in the <literal>routes</literal>
   field displayed at the end of the staging logs. For example, the
   application route could be
   <replaceable>question2answer.example.com</replaceable>.
  </para>

  <para>
   Press the button to prepare the database. When the database is ready,
   further verify by creating an initial user and posting some test questions.
  </para>
 </sect1>

 <!-- Begin optional features -->

 <sect1 xml:id="sec-cap-aks-ldap">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &ldap;
 </sect1>

 <!-- End optional features -->

 <!-- sect1 for PV resizing -->
 <!-- &resize-persistent-volume; -->

 <sect1 xml:id="sec-cap-aks-add-capacity">
  <title>Expanding Capacity of a &cap; Deployment on &aks;</title>

  <para>
   If the current capacity of your &cap; deployment is insufficient for your
   workloads, you can expand the capacity using the procedure in this section.
  </para>

  <para>
   These instructions assume you have followed the procedure in
   <xref linkend="cha-cap-depl-aks"/> and have a running &cap; deployment on
   &aks;. The instructions below will use environment variables defined in
   <xref linkend="sec-cap-create-aks-instance"/>.
  </para>

  <procedure>
   <step>
    <para>
     Get the current number of &kube; nodes in the cluster.
    </para>
<screen>&prompt.user;export OLD_NODE_COUNT=$(kubectl get nodes --output json | jq '.items | length')</screen>
   </step>
   <step>
    <para>
     Set the number of &kube; nodes the cluster will be expanded to. Replace the
     example value with the number of nodes required for your workload.
    </para>
<screen>&prompt.user;export NEW_NODE_COUNT=<replaceable>5</replaceable></screen>
   </step>
   <step>
    <para>
     <!-- https://docs.microsoft.com/en-us/azure/aks/scale-cluster -->
     Increase the &kube; node count in the cluster.
    </para>
<screen>&prompt.user;az aks scale --resource-group $RG_NAME --name $AKS_NAME \
--node-count $NEW_NODE_COUNT \
--nodepool-name $NODEPOOL_NAME
</screen>
   </step>
   <step>
    <para>
     Verify the new nodes are in a <literal>Ready</literal> state before proceeding.
    </para>
<screen>&prompt.user;kubectl get nodes</screen>
   </step>
   <step>
    <para>
     Add or update the following in your
     &values-filename; file to increase the number of
     <literal>diego-cell</literal> in your &cap; deployment. Replace the
     example value with the number required by your workflow.
    </para>
<screen>sizing:
  diego_cell:
    instances: <replaceable>5</replaceable>
</screen>
   </step>
   <step>
    <para>
     Perform a <command>helm upgrade</command> to apply the change.
    </para>
<screen>&prompt.user;helm upgrade kubecf suse/kubecf \
--values &values-file; \
--version &kubecf_chart;
</screen>
   </step>
   <step>
    <para>
     Monitor progress of the additional <literal>diego-cell</literal> pods:
    </para>
<screen>&prompt.user;watch --color 'kubectl get pods --namespace kubecf'</screen>
   </step>
  </procedure>
 </sect1>
</chapter>
