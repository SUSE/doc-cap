<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha-cap-depl-aks"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Deploying &productname; on &aks-full; (AKS)</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 &readmefirst;
 <para>
  &productname; supports deployment on &aks-full;
  (AKS), Microsoft's managed &kube; service. This chapter describes the steps
  for preparing Azure for a &productname; deployment, deployed with the default
  Azure Standard SKU load balancer (see
  <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/load-balancer-standard"/>).
 </para>
 <para>
  In &kube; terminology a node used to be a minion, which was the name for a
  worker node. Now the correct term is simply node (see
  <link xlink:href="https://kubernetes.io/docs/concepts/architecture/nodes/"></link>).
  This can be confusing, as computing nodes have traditionally been defined as
  any device in a network that has an IP address. In Azure they are called
  agent nodes. In this chapter we call them agent nodes or &kube; nodes.
 </para>
 <sect1 xml:id="sec-cap-prereqs-aks">
  <title>Prerequisites</title>

  <para>
   The following are required to deploy and use &productname; on AKS:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>az</command>, the Azure command line client. See
     <link xlink:href="https://docs.microsoft.com/en-us/cli/azure/?view=azure-cli-latest"/>
     for more information and installation instructions.
    </para>
   </listitem>
   <listitem>
    <para>
     A &ms; Azure account. For details, refer to
     <link xlink:href="https://azure.microsoft.com"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Your Azure account has sufficient quota. The minimal installation described
     in this chapter require 24 vCPUs. If your account has insufficient quota,
     you can request a quota increase by going to
     <link xlink:href="https://docs.microsoft.com/en-us/azure/azure-supportability/resource-manager-core-quotas-request"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     A SSH key that can be used for access to the nodes of the cluster. 
    </para>
   </listitem>

   <!-- listitems: Install steps and links -->
   &cfcli-prereq;
   &kubectl-prereq;
   &jq-prereq;
   &curl-prereq;
   &sed-prereq;
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sec-cap-create-aks-instance">
  <title>Create Resource Group and AKS Instance</title>

  <para>
   Log in to your Azure account, which should have the
   <literal>Contributor</literal> role.
  </para>

<screen>&prompt.user;az login</screen>

  <para>
  </para>

  <para>
   You can set up an AKS cluster with an automatically generated service
   principal. Note that to be be able to create a service principal your user
   account must have permissions to register an application with your Azure
   Active Directory tenant, and to assign the application to a role in your
   subscription. For details, see <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#automatically-create-and-use-a-service-principal"/>.
  </para>
  
  <para>
   Alternatively, you can specify an existing service principal but the service
   principal must have sufficient rights to be able to create resources at the
   appropriate level, for example resource group, subscription etc. For more
   details please see:
  </para>

  <itemizedlist>
   <listitem>
    <para>
      Create a service principal: <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#manually-create-a-service-principal"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Create a role assignment for the service principal, at the subscription or
     resource group level: <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#delegate-access-to-other-azure-resources"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Create the cluster with the service principal: <link xlink:href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#specify-a-service-principal-for-an-aks-cluster"/>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Specify the following additional parameters for creating the cluster: node
   count, a username for SSH access to the nodes, SSH key, VM type, VM disk size
   and optionally, the &kube; version and a nodepool name.
  </para>

<screen>&prompt.user;az aks create --resource-group <replaceable>my-resource-group</replaceable> --name <replaceable>cap-aks</replaceable> \
 --node-count <replaceable>3</replaceable> --admin-username <replaceable>cap-user</replaceable> \
 --ssh-key-value <replaceable>/path/to/some_key.pub</replaceable> --node-vm-size <replaceable>Standard_DS4_v2</replaceable> \
 --node-osdisk-size <replaceable>&node_size;</replaceable> --nodepool-name <replaceable>mypool</replaceable>
</screen>
<!-- The nodepool's name above is without hyphen because AKS apparently stopped
supporting alphanumeric characters in nodepool names. -->

  <para>
   For more <command>az aks create</command> options see
   <link xlink:href="https://docs.microsoft.com/en-us/cli/azure/aks?view=azure-cli-latest#az-aks-create"/>.
  </para>

  <para>
   This takes a few minutes. When it is completed, fetch your
   <command>kubectl</command> credentials. The default behavior for <command>az
   aks get-credentials</command> is to merge the new credentials with the
   existing default configuration, and to set the new credentials as as the
   current &kube; context. The context name is your AKS_NAME value. You should
   first backup your current configuration, or move it to a different location,
   then fetch the new credentials:
  </para>

<screen>&prompt.user;az aks get-credentials --resource-group $RG_NAME --name $AKS_NAME
 Merged "cap-aks" as current context in /home/&exampleuser_plain;/.kube/config</screen>

  <para>
   Verify that you can connect to your cluster:
  </para>

<screen>&prompt.user;kubectl get nodes</screen>

  <para>
   When all nodes are in a ready state and all pods are running, proceed to the
   next steps.
  </para>
 </sect1>

  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &install-helm;

 <sect1 xml:id="sec-cap-aks-storage">
  &storage-class;
 </sect1>

 <sect1 xml:id="sec-cap-aks-config">
  <title>Deployment Configuration</title>
  <para>
   The following file, &values-filename;, provides a
   minimal example deployment configuration.
  </para>

  &values-file-changes;

  &supported-domains;

  &example-config;

 </sect1>

 <!-- Begin optional features -->

 <sect1 xml:id="sec-cap-aks-certificates">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &certificates;
 </sect1>

 <sect1 xml:id="sec-cap-aks-ingress">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &ingress-controller;
 </sect1>

 <sect1 xml:id="sec-cap-aks-affinity">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &affinity;
 </sect1>

 <sect1 xml:id="sec-cap-aks-high-availability">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &high-availability;
 </sect1>

 <sect1 xml:id="sec-cap-aks-external-blobstore">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &external-blobstore;
 </sect1>

 <sect1 xml:id="sec-cap-aks-external-database">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &external-database;
 </sect1>

 <!-- End optional features -->

 <sect1 xml:id="sec-cap-addrepo-aks">
  <title>Add the &kube; Charts Repository</title>

  <para>
   Download the &suse; &kube; charts repository with &helm;:
  </para>

<screen>&prompt.user;helm repo add <replaceable>suse</replaceable> https://kubernetes-charts.suse.com/</screen>

  <para>
   You may replace the example <replaceable>suse</replaceable> name with any
   name. Verify with <command>helm</command>:
  </para>

<screen>&prompt.user;helm repo list
NAME       URL
stable     https://kubernetes-charts.storage.googleapis.com
local      http://127.0.0.1:8879/charts
suse       https://kubernetes-charts.suse.com/
</screen>

  <para>
   List your chart names, as you will need these for some operations:
  </para>

&helm-search-suse;

 </sect1>
 <sect1 xml:id="sec-cap-cap-on-aks">
  <title>Deploying &productname;</title>
  <para>
   This section describes how to deploy &productname; with a Azure Standard SKU
   load balancer.
  </para>

  &kubecf-operator-versions;

  <sect2 xml:id="sec-cap-aks-deploy-operator">
   &deploy-operator;
  </sect2>

  <sect2 xml:id="sec-cap-aks-deploy-kubecf">
   <title>Deploy &kubecf;</title>
   <procedure>
    &deploy-kubecf;
    <step>
     <para>
      Create DNS A records for the public services.
     </para>
     &dns-mappings;
    </step>
    <step>
     <para>
      When all pods are fully ready, verify your deployment. See <xref linkend="sec-pod-status"/> for more information.
     </para>
     &cf-auth;
    </step>
   </procedure>
  </sect2>
 </sect1>

 <!-- Begin optional features -->

 <sect1 xml:id="sec-cap-aks-ldap">
  <!-- Entry defined in xml/repeated-content-decl.ent -->
  &ldap;
 </sect1>

 <!-- End optional features -->

 <!-- sect1 for PV resizing -->
 <!-- &resize-persistent-volume; -->

 <sect1 xml:id="sec-cap-aks-add-capacity">
  <title>Expanding Capacity of a &cap; Deployment on &aks;</title>

  <para>
   If the current capacity of your &cap; deployment is insufficient for your
   workloads, you can expand the capacity using the procedure in this section.
  </para>

  <para>
   These instructions assume you have followed the procedure in
   <xref linkend="cha-cap-depl-aks"/> and have a running &cap; deployment on
   &aks;. The instructions below will use environment variables defined in
   <xref linkend="sec-cap-create-aks-instance"/>.
  </para>

  <procedure>
   <step>
    <para>
     Get the current number of &kube; nodes in the cluster.
    </para>
<screen>&prompt.user;export OLD_NODE_COUNT=$(kubectl get nodes --output json | jq '.items | length')</screen>
   </step>
   <step>
    <para>
     Set the number of &kube; nodes the cluster will be expanded to. Replace the
     example value with the number of nodes required for your workload.
    </para>
<screen>&prompt.user;export NEW_NODE_COUNT=<replaceable>5</replaceable></screen>
   </step>
   <step>
    <para>
     <!-- https://docs.microsoft.com/en-us/azure/aks/scale-cluster -->
     Increase the &kube; node count in the cluster.
    </para>
<screen>&prompt.user;az aks scale --resource-group $RG_NAME --name $AKS_NAME \
--node-count $NEW_NODE_COUNT \
--nodepool-name $NODEPOOL_NAME
</screen>
   </step>
   <step>
    <para>
     Verify the new nodes are in a <literal>Ready</literal> state before proceeding.
    </para>
<screen>&prompt.user;kubectl get nodes</screen>
   </step>
   <step>
    <para>
     Add or update the following in your
     &values-filename; file to increase the number of
     <literal>diego-cell</literal> in your &cap; deployment. Replace the
     example value with the number required by your workflow.
    </para>
<screen>sizing:
  diego_cell:
    instances: <replaceable>5</replaceable>
</screen>
   </step>
   <step>
    <para>
     Perform a <command>helm upgrade</command> to apply the change.
    </para>
<screen>&prompt.user;helm upgrade kubecf suse/kubecf \
--namespace <replaceable>kubecf</replaceable> \
--values &values-file; \
--version &kubecf_chart;
</screen>
   </step>
   <step>
    <para>
     Monitor progress of the additional <literal>diego-cell</literal> pods:
    </para>
<screen>&prompt.user;watch --color 'kubectl get pods --namespace kubecf'</screen>
   </step>
  </procedure>
 </sect1>
</chapter>
