<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha-cap-depl-troubleshooting"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Troubleshooting</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <para>
  Cloud stacks are complex, and debugging deployment issues often requires
  digging through multiple layers to find the information you need. Remember
  that the &kubecf; releases must be deployed in the correct order, and that each
  release must deploy successfully, with no failed pods, before deploying the
  next release.
 </para>
 <para>
  Before proceeding with in depth troubleshooting, ensure the following have
  been met as defined in the Support Statement at <xref linkend="sec-cap-support-statement"/>.
 </para>
 <orderedlist>
   <listitem>
    <para>
     The &kube; cluster satisfies the Requirements listed here at
     <link xlink:href="https://documentation.suse.com/suse-cap/&productnumber;/html/cap-guides/cha-cap-depl-kube-requirements.html#sec-cap-changes-kube-reqs"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     The <filename>kube-ready-state-check.sh</filename> script has been run on
     the target &kube; cluster and does not show any configuration problems.
    </para>
   </listitem>
   <listitem>
    <para>
     A &suse; Services or Sales Engineer has verified that &productname; works
     correctly on the target &kube; cluster.
    </para>
   </listitem>
  </orderedlist>
 <sect1 xml:id="sec-cap-tbl-logging">
  <title>Logging</title>

  <para>
   There are two types of logs in a deployment of &productname;, applications
   logs and component logs. The following provides a brief overview of each log
   type and how to retrieve them for monitoring and debugging use.
  </para>

  <!-- itemizedlist of log types and how to fetch them -->
  &log-types-and-fetch;
 </sect1>
 <sect1  xml:id="sec-cap-tbl-supportconfig">
  <title>Using Supportconfig</title>

  <para>
   If you ever need to request support, or just want to generate detailed
   system information and logs, use the <command>supportconfig</command>
   utility. Run it with no options to collect basic system information, and
   also cluster logs including &docker;, etcd, flannel, and Velum.
   <command>supportconfig</command> may give you all the information you need.
  </para>

  <para>
   <command>supportconfig -h</command> prints the options. Read the "Gathering
   System Information for Support" chapter in any &sle; &admin; to
   learn more.
  </para>
 </sect1>
 <sect1 xml:id="sec-cap-tbl-toolong">
  <title>Deployment Is Taking Too Long</title>

  <para>
   A deployment step seems to take too long, or you see that some pods are not
   in a ready state hours after all the others are ready, or a pod shows a lot
   of restarts. This example shows not-ready pods many hours after the others
   have become ready:
  </para>

<screen>&prompt.user;kubectl get pods --namespace kubecf
NAME                     READY STATUS    RESTARTS  AGE
router-3137013061-wlhxb  0/1   Running   0         16h
routing-api-0            0/1   Running   0         16h</screen>

  <para>
   The <literal>Running</literal> status means the pod is bound to a node and
   all of its containers have been created. However, it is not
   <literal>Ready</literal>, which means it is not ready to service requests.
   Use <command>kubectl</command> to print a detailed description of pod events
   and status:
  </para>

<screen>&prompt.user;kubectl describe pod --namespace kubecf router-3137013061-wlhxb</screen>

  <para>
   This prints a lot of information, including IP addresses, routine events,
   warnings, and errors. You should find the reason for the failure in this
   output.
  </para>

  <important>
&deployment-pod-status;
  </important>
 </sect1>
 <sect1 xml:id="sec-cap-tbl-rebuild-depl">
  <title>Deleting and Rebuilding a Deployment</title>

  <para>
   There may be times when you want to delete and rebuild a deployment, for
   example when there are errors in your
   &values-filename; file, you wish to test
   configuration changes, or a deployment fails and you want to try it again.
   This has five steps: first delete the StatefulSets of the namespace
   associated with the release or releases you want to re-deploy, then delete
   the release or releases, delete its namespace, then re-create the namespace
   and re-deploy the release.
  </para>

  <para>
   The namespace is also deleted as part of the process because the
   <literal>kubecf</literal>
   namespace contain generated secrets which Helm is not aware of and will not
   remove when a release is deleted. When deleting a release, busy systems may
   encounter timeouts. By first deleting the StatefulSets, it ensures that this
   operation is more likely to succeed. Using the <command>delete
   statefulsets</command> command requires <command>kubectl</command> v1.9.6 or
   newer.
  </para>

  <para>
   Use <command>helm</command> to see your releases:
  </para>

<screen>&prompt.user;helm list
NAME            REVISION  UPDATED                  STATUS    CHART           NAMESPACE
<replaceable>susecf-console</replaceable>  1         Tue Aug 14 11:53:28 2018 DEPLOYED  &stratos_chart;   stratos
<replaceable>kubecf</replaceable>      1         Tue Aug 14 10:58:16 2018 DEPLOYED  &kubecf_chart;       kubecf
</screen>

  <para>
   This example deletes the <literal>kubecf</literal> release and
   <literal>kubecf</literal> namespace:
  </para>

<screen>&prompt.user;kubectl delete statefulsets --all --namespace kubecf
statefulset "adapter" deleted                                                   
statefulset "api-group" deleted                                                 
... 

&prompt.user;helm delete kubecf
release "kubecf" deleted

&prompt.user;kubectl delete namespace kubecf
namespace "kubecf" deleted</screen>

 <para>
   Then you can start over. Be sure to create new release and namespace names.
  </para>
 </sect1>
 <sect1 xml:id="sec-cap-tbl-kubectl-queries">
  <title>Querying with Kubectl</title>

  <para>
   You can safely query with <command>kubectl</command> to get information
   about resources inside your &kube; cluster. <command>kubectl cluster-info
   dump | tee clusterinfo.txt</command> outputs a large amount of information
   about the &kube; master and cluster services to a text file.
  </para>

  <para>
   The following commands give more targeted information about your cluster.
  </para>

  <itemizedlist>
   <listitem>
    <para>
     List all cluster resources:
    </para>
<screen>&prompt.user;kubectl get all --all-namespaces</screen>
   </listitem>
   <listitem>
    <para>
     List all of your running pods:
    </para>
<screen>&prompt.user;kubectl get pods --all-namespaces</screen>
   </listitem>
   <listitem>
    <para>
     List all of your running pods, their internal IP addresses, and which
     &kube; nodes they are running on:
    </para>
<screen>&prompt.user;kubectl get pods --all-namespaces --output wide</screen>
   </listitem>
   <listitem>
    <para>
     See all pods, including those with Completed or Failed statuses:
    </para>
<screen>&prompt.user;kubectl get pods --show-all --all-namespaces</screen>
   </listitem>
   <listitem>
    <para>
     List pods in one namespace:
    </para>
<screen>&prompt.user;kubectl get pods --namespace kubecf</screen>
   </listitem>
   <listitem>
    <para>
     Get detailed information about one pod:
    </para>
<screen>&prompt.user;kubectl describe --namespace kubecf po/diego-cell-0</screen>
   </listitem>
   <listitem>
    <para>
     Read the log file of a pod:
    </para>
<screen>&prompt.user;kubectl logs --namespace kubecf po/diego-cell-0</screen>
   </listitem>
   <listitem>
    <para>
     List all &kube; nodes, then print detailed information about a single
     node:
    </para>
<screen>&prompt.user;kubectl get nodes
&prompt.user;kubectl describe node 6a2752b6fab54bb889029f60de6fa4d5.infra.caasp.local</screen>
   </listitem>
   <listitem>
    <para>
     List all containers in all namespaces, formatted for readability:
    </para>
<screen>&prompt.user;kubectl get pods --all-namespaces --output jsonpath="{..image}" |\
tr -s '[[:space:]]' '\n' |\
sort |\
uniq -c</screen>
   </listitem>
   <listitem>
    <para>
     These two commands check node capacities, to verify that there are enough
     resources for the pods:
    </para>
<screen>&prompt.user;kubectl get nodes --output yaml | grep '\sname\|cpu\|memory'
&prompt.user;kubectl get nodes --output json | \
jq '.items[] | {name: .metadata.name, cap: .status.capacity}'</screen>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sec-cap-tbl-autoscaler-metrics-lock">
  <title><literal>autoscaler-metrics</literal> Pod Liquibase Error</title>

  <para>
   In some situations, the <literal>autoscaler-metrics</literal> pod may fail to
   reach a fully ready state due to a Liquibase error,
   <literal>liquibase.exception.LockException: Could not acquire change log lock
   </literal>.
  </para>
  <para>
   When this occurs, use the following procedure to resolve the issue.
  </para>
  <procedure>
   <step>
    <para>
     Verify whether the error has occurred by examining the logs.
    </para>
<screen>&prompt.user;kubectl logs autoscaler-metrics-0 autoscaler-metrics --follow --namespace kubecf</screen>
    <para>
     If the error has occurred, the log will contain entires similar to the following.
    </para>
<screen># Starting Liquibase at Wed, 21 Aug 2019 22:38:00 UTC (version 3.6.3 built at 2019-01-29 11:34:48)
# Unexpected error running Liquibase: Could not acquire change log lock.  Currently locked by autoscaler-metrics-0.autoscaler-metrics-set.cf.svc.cluster.local (172.16.0.173) since 8/21/19, 9:20 PM
# liquibase.exception.LockException: Could not acquire change log lock.  Currently locked by autoscaler-metrics-0.autoscaler-metrics-set.cf.svc.cluster.local (172.16.0.173) since 8/21/19, 9:20 PM
#         at liquibase.lockservice.StandardLockService.waitForLock(StandardLockService.java:230)
#         at liquibase.Liquibase.update(Liquibase.java:184)
#         at liquibase.Liquibase.update(Liquibase.java:179)
#         at liquibase.integration.commandline.Main.doMigration(Main.java:1220)
#         at liquibase.integration.commandline.Main.run(Main.java:199)
#         at liquibase.integration.commandline.Main.main(Main.java:137)
</screen>
   </step>
   <step>
    <para>
     After confirming the error has occurred, use the provided Ruby script to
     recover from the error.
    </para>
    <substeps>
     <step>
      <para>
       Save the script below to a file. In this example, it is saved to a file
       named <filename>recovery-autoscaler-metrics-liquidbase-stale-lock</filename>.
      </para>
<screen>#!/usr/bin/env ruby

# This script recovers from autoscaler-metrics failing to start because it could
# not continue schema migrations.  The error looks something like:

# Starting Liquibase at Wed, 21 Aug 2019 22:38:00 UTC (version 3.6.3 built at 2019-01-29 11:34:48)
# Unexpected error running Liquibase: Could not acquire change log lock.  Currently locked by autoscaler-metrics-0.autoscaler-metrics-set.cf.svc.cluster.local (172.16.0.173) since 8/21/19, 9:20 PM
# liquibase.exception.LockException: Could not acquire change log lock.  Currently locked by autoscaler-metrics-0.autoscaler-metrics-set.cf.svc.cluster.local (172.16.0.173) since 8/21/19, 9:20 PM
#         at liquibase.lockservice.StandardLockService.waitForLock(StandardLockService.java:230)
#         at liquibase.Liquibase.update(Liquibase.java:184)
#         at liquibase.Liquibase.update(Liquibase.java:179)
#         at liquibase.integration.commandline.Main.doMigration(Main.java:1220)
#         at liquibase.integration.commandline.Main.run(Main.java:199)
#         at liquibase.integration.commandline.Main.main(Main.java:137)

require 'json'
require 'open3'

EXPECTED_ERROR='Could not acquire change log lock.  Currently locked by'

def capture(*args)
    stdout, status = Open3.capture2(*args)
    return stdout if status.success?
    cmd = args.dup
    cmd.shift while Hash.try_convert(cmd.first)
    cmd.pop while Hash.try_convert(cmd.last)
    fail %Q&lt;"#{cmd.join(' ')}" failed with exit status #{status.exitstatus}>
end

def namespace
    $namespace ||= JSON.parse(capture('helm list --output json'))['Releases']
        .select { |r| r['Status'].downcase == 'deployed' }
        .select { |r| r['Chart'].start_with? 'cf-' }
        .first['Namespace']
end

def run(*args)
    Process.wait Process.spawn(*args)
    return if $?.success?
    cmd = args.dup
    cmd.shift while Hash.try_convert(cmd.first)
    cmd.pop while Hash.try_convert(cmd.last)
    fail %Q&lt;"#{cmd.join(' ')}" failed with exit status #{$?.exitstatus}>
end

postgres_pod = JSON.load(capture('kubectl', 'get', 'pods',
    '--namespace', namespace,
    '--selector', 'skiff-role-name==autoscaler-postgres',
    '--output', 'json'))['items']
    .find { |pod|
        pod['status']['conditions']
            .find {|status| status['type'] == 'Ready'}['status'] == 'True'
    }['metadata']['name']

psql_binary = capture('kubectl', 'exec', postgres_pod,
    '--namespace', namespace,
    '--', 'sh', '-c', 'echo /var/vcap/packages/postgres-*/bin/psql').split.first

run 'kubectl', 'exec', postgres_pod,
    '--namespace', namespace,
    '--',
    psql_binary,
    '--username', 'postgres',
    '--dbname', 'autoscaler',
    '--command', 'SELECT * FROM databasechangeloglock'

locked_bys = (1..Float::INFINITY).each do |count|
    STDOUT.printf "\rWaiting for pod to get stuck (try %s)...", count
    candidate_locked_bys = capture('kubectl', 'get', 'pods',
                        '--namespace', namespace,
                        '--selector', 'skiff-role-name==autoscaler-metrics',
                        '--output', 'jsonpath={.items[*].metadata.name}')
        .split
        .map do |pod_name|
            capture('kubectl', 'logs', pod_name,
                    '--namespace', namespace,
                    '--container', 'autoscaler-metrics')
        end
        .select { |message| message.include? EXPECTED_ERROR }
        .map { |message| /Currently locked by (.*?) since /.match(message)[1]}

    break candidate_locked_bys unless candidate_locked_bys.empty?
    sleep 1
end
puts '' # new line after the wait
locked_bys.each do |locked_by|
    puts "Releasing lock for #{locked_by}"
    run 'kubectl', 'exec', postgres_pod,
        '--namespace', namespace,
        '--',
        psql_binary,
        '--username', 'postgres',
        '--dbname', 'autoscaler',
        '--command', %Q&lt;UPDATE databasechangeloglock SET locked = FALSE WHERE lockedby = '#{locked_by}'>
end
</screen>
     </step>
     <step>
      <para>
       Run the script.
      </para>
<screen>&prompt.user;ruby <replaceable>recovery-autoscaler-metrics-liquidbase-stale-lock</replaceable></screen>
      <para>
       All <literal>autoscaler</literal> pods should now enter a fully ready state.
      </para>
     </step>
    </substeps>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec-cap-tbl-buildpack-with-stack">
  <title><literal>api-group</literal> Pod Not Ready after Buildpack Update</title>
  <para>
   When a built-in buildpack is updated as described in one of the scenarios
   below, the <literal>api-group</literal> pod will fail to reach a fully ready
   state upon restart. A built-in buildpack is a buildpack that is included as
   part of a &productname; release and has no stack association by default.
  </para>
  <para>
   The following scenarios can result in the <literal>api-group</literal> not
   being fully ready:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     A built-in buildpack is assigned a stack association. For example:
    </para>
<screen>&prompt.user;cf update-buildpack <replaceable>ruby_buildpack</replaceable> --assign-stack <replaceable>sle15</replaceable></screen>
   </listitem>
   <listitem>
    <para>
     A built-in buildpack is updated to to a version with an inherent stack
     association, such as those provided by upstream &cf;. For example:
    </para>
<screen>&prompt.user;cf update-buildpack <replaceable>ruby_buildpack</replaceable> -p <replaceable>https://github.com/cloudfoundry/ruby-buildpack/releases/download/v1.7.43/ruby-buildpack-cflinuxfs3-v1.7.43.zip</replaceable></screen>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="sec-cap-tbl-buildpack-with-stack-recovery-prevention">
   <title>Recovery and Prevention</title>
   <para>
    In order to bring the <literal>api-group</literal> pod back to a fully ready
    state, use the following procedure.
   </para>
   <procedure>
    <step>
     <para>
      Delete the buildpack that was updated to have a stack association.
     </para>
<screen>&prompt.user;cf delete-buildpack <replaceable>ruby_buildpack</replaceable></screen>
    </step>
    <step>
     <para>
      Restart the <literal>api-group</literal> pod.
     </para>
<screen>&prompt.user;kubectl delete pod api-group-0 --namespace <replaceable>kubecf</replaceable></screen>
    </step>
   </procedure>
   <para>
    In order to use a buildpack with a stack association and not encounter the
    issue described in this section, do the following. Instead of updating one
    of the built-in buildpacks to either assign a stack or update to one with an
    inherent stack association, create a new buildpack with the desired buildpack
    files and associated stack.
   </para>
<screen>&prompt.user;cf create-buildpack <replaceable>ruby_cflinuxfs3</replaceable> <replaceable>https://github.com/cloudfoundry/ruby-buildpack/releases/download/v1.7.41/ruby-buildpack-cflinuxfs3-v1.7.41.zip</replaceable> <replaceable>1</replaceable> <replaceable>--enable</replaceable></screen>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-cap-tbl-admission-webhook">
  <title>Admission webhook denied</title>
  <para>
    When switching back to Diego from Eirini, the error below can occur:
  </para>
<screen>
&prompt.user;helm install kubecf <replaceable>kubecf.tgz</replaceable> --namespace <replaceable>kubecf</replaceable> --values <replaceable>kubecf-values.yaml</replaceable>
Error: admission webhook "validate-boshdeployment.quarks.cloudfoundry.org" denied the request: Failed to resolve manifest: Failed to interpolate ops 'kubecf-user-provided-properties' for manifest 'kubecf': Applying ops on manifest obj failed in interpolator: Expected to find exactly one matching array item for path '/instance_groups/name=eirini' but found 0
  </screen>
  <para>
    To avoid this error, remove the <literal>eirini-persi-broker</literal> configuration
    before running the command.
  </para>
 </sect1>
 <sect1 xml:id="sec-cap-tbl-helm-namespace">
  <title>Namespace does not exist</title>
  <para>
    When running a &helm; command, an error occurs stating that a namespace does not
    exist. To avoid this error, create the namespace manually with <command>kubectl</command>; before
    running the command:
  </para>
<screen>
&prompt.user;kubectl create namespace <replaceable>name</replaceable>
  </screen>
 </sect1>
</chapter>
