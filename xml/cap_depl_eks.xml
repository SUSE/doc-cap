<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha.cap.eks"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Deploying &productname; on Amazon EKS</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <important>
     &readmefirst;
 </important>
 <para>
  This chapter describes how to deploy &productname; on Amazon EKS, using
  Amazon's Elastic Load Balancer to provide fault-tolerant access to your
  cluster.
 </para>
 <sect1 xml:id="sec.cap.eks-prereqs">
  <title>Prerequisites</title>

  <para>
   You need an <link xlink:href="https://aws.amazon.com/">Amazon EKS
   account</link>. See
   <link xlink:href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started.html">Getting
   Started with Amazon EKS</link> for instructions on creating a &kube; cluster
   for your &productname; deployment.
  </para>

  <para>
   When you create your cluster, use node sizes that are at least
   <literal>t2.large</literal>. The <literal>NodeVolumeSize</literal> must be a
   minimum of 80 GB.
  </para>

  <para>
   Take note of special configurations that are required to successfully deploy
   &productname; on EKS in <xref linkend="sec.cap.install-scf-eks"/>.
  </para>

  <para>
   <xref linkend="sec.cap.eks-iam"/> provides guidance on configuring Identity
   and Access Management (IAM) for your users.
  </para>
 </sect1>
 <sect1 xml:id="sec.cap.eks-iam">
  <title>IAM Requirements for EKS</title>

  <para>
   These IAM policies provide sufficient access to use EKS.
  </para>

  <sect2 xml:id="sec.cap.eks-unscoped">
   <title>Unscoped Operations</title>
   <para>
    Some of these permissions are very broad. They are difficult to scope
    effectively, in part because many resources are created and named
    dynamically when deploying an EKS cluster using the
    <link xlink:href="https://console.aws.amazon.com/cloudformation">
    CloudFormation</link> console. It may be helpful to enforce certain naming
    conventions, such as prefixing cluster names with
    <varname>${aws:username}</varname> for pattern-matching in
    <guimenu>Conditions</guimenu>. However, this requires special consideration
    beyond the EKS deployment guide, and should be evaluated in the broader
    context of organizational IAM policies.
   </para>
<screen>{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "UnscopedOperations",
            "Effect": "Allow",
            "Action": [
                "cloudformation:CreateUploadBucket",
                "cloudformation:EstimateTemplateCost",
                "cloudformation:ListExports",
                "cloudformation:ListStacks",
                "cloudformation:ListImports",
                "cloudformation:DescribeAccountLimits",
                "eks:ListClusters",
                "cloudformation:ValidateTemplate",
                "cloudformation:GetTemplateSummary",
                "eks:CreateCluster"
            ],
            "Resource": "*"
        },
        {
            "Sid": "EffectivelyUnscopedOperations",
            "Effect": "Allow",
            "Action": [
                "iam:CreateInstanceProfile",
                "iam:DeleteInstanceProfile",
                "iam:GetRole",
                "iam:DetachRolePolicy",
                "iam:RemoveRoleFromInstanceProfile",
                "cloudformation:*",
                "iam:CreateRole",
                "iam:DeleteRole",
                "eks:*"
            ],
            "Resource": [
                "arn:aws:eks:*:*:cluster/*",
                "arn:aws:cloudformation:*:*:stack/*/*",
                "arn:aws:cloudformation:*:*:stackset/*:*",
                "arn:aws:iam::*:instance-profile/*",
                "arn:aws:iam::*:role/*"
            ]
        }
    ]
}</screen>
  </sect2>

  <sect2 xml:id="sec.cap.eks-scoped">
   <title>Scoped Operations</title>
   <para>
    These policies deal with sensitive access controls, such as passing roles
    and attaching/detaching policies from roles.
   </para>
   <para>
    This policy, as written, allows unrestricted use of only customer-managed
    policies, and not Amazon-managed policies. This prevents potential security
    holes such as attaching the <literal>IAMFullAccess</literal> policy to a
    role. If you are using roles in a way that would be undermined by this, you
    should strongly consider integrating a
    <link xlink:href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html">Permissions
    Boundary</link> before using this policy.
   </para>
<screen>{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "UseCustomPoliciesWithCustomRoles",
            "Effect": "Allow",
            "Action": [
                "iam:DetachRolePolicy",
                "iam:AttachRolePolicy"
            ],
            "Resource": [
                "arn:aws:iam::&lt;YOUR_ACCOUNT_ID>:role/*",
                "arn:aws:iam::&lt;YOUR_ACCOUNT_ID>:policy/*"
            ],
            "Condition": {
                "ForAllValues:ArnNotLike": {
                    "iam:PolicyARN": "arn:aws:iam::aws:policy/*"
                }
            }
        },
        {
            "Sid": "AllowPassingRoles",
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "arn:aws:iam::&lt;YOUR_ACCOUNT_ID>:role/*"
        },
        {
            "Sid": "AddCustomRolesToInstanceProfiles",
            "Effect": "Allow",
            "Action": "iam:AddRoleToInstanceProfile",
            "Resource": "arn:aws:iam::&lt;YOUR_ACCOUNT_ID>:instance-profile/*"
        },
        {
            "Sid": "AssumeServiceRoleForEKS",
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Resource": "arn:aws:iam::&lt;YOUR_ACCOUNT_ID>:role/&lt;EKS_SERVICE_ROLE_NAME>"
        },
        {
            "Sid": "DenyUsingAmazonManagedPoliciesUnlessNeededForEKS",
            "Effect": "Deny",
            "Action": "iam:*",
            "Resource": "arn:aws:iam::aws:policy/*",
            "Condition": {
                "ArnNotEquals": {
                    "iam:PolicyARN": [
                        "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy",
                        "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy",
                        "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
                    ]
                }
            }
        },
        {
            "Sid": "AllowAttachingSpecificAmazonManagedPoliciesForEKS",
            "Effect": "Allow",
            "Action": [
                "iam:DetachRolePolicy",
                "iam:AttachRolePolicy"
            ],
            "Resource": "*",
            "Condition": {
                "ArnEquals": {
                    "iam:PolicyARN": [
                        "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy",
                        "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy",
                        "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
                    ]
                }
            }
        }
    ]
}</screen>
  </sect2>
 </sect1>

 <!-- sect1 for helm client and tiller installation -->
 &install-helm-tiller;

 <sect1 xml:id="sec.cap.eks-storage-class">
  <title>Default Storage Class</title>

  <para>
   This example creates a simple storage class for your cluster in
   <filename>storage-class.yaml</filename>:
  </para>

<screen>apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp2
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
  labels:
    kubernetes.io/cluster-service: "true"
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2</screen>

  <para>
   Then apply the new storage class configuration with this command:
  </para>

<screen>&prompt.user;kubectl create -f storage-class.yaml</screen>
 </sect1>
 <sect1 xml:id="sec.cap.eks-secgroup-rules">
  <title>Security Group rules</title>

  <para>
   In your EC2 virtual machine list, add the following rules to the security
   group to any one of your nodes:
  </para>

<screen>Type		   Protocol     Port Range      Source          Description
HTTP               TCP          80              0.0.0.0/0       CAP HTTP
Custom TCP Rule    TCP          2793            0.0.0.0/0       CAP UAA
Custom TCP Rule    TCP          2222            0.0.0.0/0       CAP SSH
Custom TCP Rule    TCP          4443            0.0.0.0/0       CAP WSS
Custom TCP Rule    TCP          443             0.0.0.0/0       CAP HTTPS
Custom TCP Rule    TCP          20000-20009     0.0.0.0/0       TCP Routing</screen>
 </sect1>
 <sect1 xml:id="sec.cap.eks.dns">
  <title>DNS Configuration</title>

  <para>
   Creation of the Elastic Load Balancer is triggered by a setting in the &cap;
   deployment configuration file. First deploy <literal>uaa</literal>, then
   create CNAMEs for your domain and <literal>uaa</literal> subdomains (see the
   table below). Then deploy <literal>scf</literal>, and create the appropriate
   <literal>scf</literal> CNAMEs. This is described in more detail in the
   deployment sections.
  </para>

  <para>
   The following table lists the required domain and sub-domains, using
   <literal>example.com</literal> as the example domain:
  </para>

&dns-tables;

 </sect1>
 <sect1 xml:id="sec.cap.eks-configuration">
  <title>Deployment Configuration</title>

  <para>
   Use this example <filename>scf-config-values.yaml</filename> as a template
   for your configuration.
  </para>

<screen>### example deployment configuration file
### scf-config-values.yaml

env:
  DOMAIN: <replaceable>example.com</replaceable>
  UAA_HOST: uaa.<replaceable>example.com</replaceable>
  UAA_PORT: 2793
  
  GARDEN_ROOTFS_DRIVER: overlay-xfs
  GARDEN_APPARMOR_PROFILE: ""
  
services:
  loadbalanced: true
  
kube:
  storage_class:
    # Change the value to the storage class you use
    persistent: "<replaceable>gp2</replaceable>"
    shared: "<replaceable>gp2</replaceable>"

  # The default registry images are fetched from
  registry:
    hostname: "registry.suse.com"
    username: ""
    password: ""
  organization: "cap"
  
secrets:
  # Create a very strong password for user 'admin'
  CLUSTER_ADMIN_PASSWORD: <replaceable>password</replaceable>

  # Create a very strong password, and protect it because it
  # provides root access to everything
  UAA_ADMIN_CLIENT_SECRET: <replaceable>password</replaceable>
</screen>

  <!-- Explains usage of some Helm values used in the example/minimal values.yaml-->
  &config-value-usage;

  <!-- Reiterates importance of this password -->
  &protect-uaa-admin-secret;

 </sect1>
 <sect1 xml:id="sec.cap.eks-deploy">
<!-- maybe change some of the content in this section to an entity (cjs, feb
      12 2019_-->

  <title>Deploying &cap;</title>

  <para>
   The following list provides an overview of &helm; commands to complete the
   deployment. Included are links to detailed descriptions.
  </para>

  <procedure>
   <step>
    <para>
     Download the &suse; &kube; charts repository
     (<xref
     linkend="sec.cap.addrepo-eks"/>)
    </para>
   </step>
   <step>
    <para>
     Deploy <literal>uaa</literal>, then create appropriate CNAMEs
     (<xref linkend="sec.cap.install-uaa-eks"/>)
    </para>
   </step>
   <step>
    <para>
     Copy the <literal>uaa</literal> secret and certificate to the
     <literal>scf</literal> namespace, deploy <literal>scf</literal>, create
     CNAMES (<xref linkend="sec.cap.install-scf-eks"/>)
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec.cap.addrepo-eks">
  <title>Add the &kube; Charts Repository</title>

  <para>
   Download the &suse; &kube; charts repository with &helm;:
  </para>

<screen>&prompt.user;helm repo add <replaceable>suse</replaceable> https://kubernetes-charts.suse.com/</screen>

  <para>
   You may replace the example <replaceable>suse</replaceable> name with any
   name. Verify with <command>helm</command>:
  </para>

<screen>&prompt.user;helm repo list
NAME            URL                                             
stable          https://kubernetes-charts.storage.googleapis.com
local           http://127.0.0.1:8879/charts                    
suse            https://kubernetes-charts.suse.com/</screen>

  <para>
   List your chart names, as you will need these for some operations:
  </para>

&helm-search-suse;

 </sect1>
 <sect1 xml:id="sec.cap.install-uaa-eks">
  <title>Deploy <literal>uaa</literal></title>

  <para>
   Use &helm; to deploy the <literal>uaa</literal> (User Account and
   Authentication) server. You may create your own release
   <literal>--name</literal>:
  </para>

<screen>&prompt.user;helm install suse/uaa \
--name <replaceable>susecf-uaa</replaceable> \
--namespace uaa \
--values scf-config-values.yaml</screen>

  <para>
   Wait until you have a successful <literal>uaa</literal> deployment before
   going to the next steps, which you can monitor with the
   <command>watch</command> command:
  </para>

<screen>&prompt.user;watch -c 'kubectl get pods --namespace uaa'</screen>

  <para>
   When the status shows RUNNING for all of the <literal>uaa</literal> pods,
   create CNAMEs for the required domains. (See
   <xref linkend="sec.cap.eks.dns"/>.) Use <command>kubectl</command> to find
   the service host names. These host names include the <literal>elb</literal>
   sub-domain, so use this to get the correct results:
  </para>

<screen>&prompt.user;kubectl get services --namespace uaa | grep elb</screen>

  <important>
&deployment-pod-status;
  </important>
 </sect1>
 <sect1 xml:id="sec.cap.install-scf-eks">
  <title>Deploy <literal>scf</literal></title>

  <para>
   Because of the way EKS runs health checks, &cap; requires an edit to one of
   the <literal>scf</literal> &helm; chart's templates, and then after a successful
   <literal>scf</literal> deployment remove a listening port from the Elastic
   Load Balancer's listeners list.
  </para>

  <para>
   Fetch and extract the <literal>scf</literal> &helm; chart:
  </para>

<screen>&prompt.user;helm fetch --untar suse/cf</screen>

  <para>
   In <filename>cf/templates/tcp-router.yaml</filename>, add the following to the
   <literal>ports</literal> section of the
   <literal>tcp-router-tcp-router-public</literal> definition:
  </para>

<screen>
- name: "healthcheck"
  port: 8080
  protocol: "TCP"
  targetPort: "healthcheck"
</screen>

  <para>
   The section should look like this:
  </para>

<screen>
    ports:
    - name: "healthcheck"
      port: 8080
      protocol: "TCP"
      targetPort: "healthcheck"
    {{- range $port := until (int .Values.sizing.tcp_router.ports.tcp_route.count) }}
    - name: "tcp-route-{{ $port }}"
      port: {{ add 20000 $port }}
      protocol: "TCP"
      targetPort: "tcp-route-{{ $port }}"
    {{- end }}
    selector:
      app.kubernetes.io/component: "tcp-router" 
      </screen>

  <para>
   Now pass your <literal>uaa</literal> secret and certificate to
   <literal>scf</literal>, then use &helm; to install &scf;
   using the modified chart directory:
  </para>

<screen>&prompt.user;SECRET=$(kubectl get pods --namespace uaa \
-o jsonpath='{.items[?(.metadata.name=="uaa-0")].spec.containers[?(.name=="uaa")].env[?(.name=="INTERNAL_CA_CERT")].valueFrom.secretKeyRef.name}')

&prompt.user;CA_CERT="$(kubectl get secret $SECRET --namespace uaa \
-o jsonpath="{.data['internal-ca-cert']}" | base64 --decode -)"

&prompt.user;helm install /path/to/cf \
--name <replaceable>susecf-scf</replaceable> \
--namespace scf \
--values scf-config-values.yaml \
--set "secrets.UAA_CA_CERT=${CA_CERT}"</screen>

  <para>
   Sit back and wait for the pods to come online:
  </para>

<screen>&prompt.user;watch -c 'kubectl get pods --namespace scf'</screen>

  <para>
   Remove port 8080 from the load balancer's listeners list:
  </para>

<screen>&prompt.user;aws elb delete-load-balancer-listeners \
--load-balancer-name  healthcheck   \
--load-balancer-ports 8080
</screen>

  <para>
   Now health checks should operate correctly. When the status shows RUNNING
   for all of the <literal>scf</literal> pods, create CNAMEs for the required
   domains. (See <xref linkend="sec.cap.eks.dns"/>) Use
   <command>kubectl</command> to find the service host names. These host names
   include the <literal>elb</literal> sub-domain, so use this to get the
   correct results:
  </para>

<screen>&prompt.user;kubectl get services --namespace scf | grep elb</screen>
 </sect1>
 <sect1 xml:id="sec.cap.aws-service-broker">
  <title>Deploying and Using the AWS Service Broker</title>

  <para>
   The <link xlink:href="https://aws.amazon.com/partners/servicebroker/">AWS
   Service Broker</link> provides integration of native AWS services with
   &suse; &cap;.
  </para>

  <sect2 xml:id="sec.cap.aws-service-broker-prereqs">
   <title>Prerequisites</title>
   <para>
    Deploying and using the AWS Service Broker requires the following:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      &cap; has been successfully deployed on Amazon EKS as described earlier
      in this chapter (see <xref linkend="cha.cap.eks"/>)
     </para>
    </listitem>
    <listitem>
     <para>
      The <link xlink:href="https://aws.amazon.com/cli/">AWS Command Line
      Interface (CLI)</link>
     </para>
    </listitem>
    <listitem>
     <para>
      The
      <link xlink:href="https://www.openssl.org/docs/man1.0.2/apps/openssl.html">OpenSSL
      command line tool</link>
     </para>
    </listitem>
    <listitem>
     <para>
      Ensure the user or role running the broker has an IAM policy set as
      specified in the
      <link xlink:href="https://github.com/awslabs/aws-servicebroker/blob/master/docs/install_prereqs.md#iam">IAM
      section of the AWS Service Broker</link> documentation on Github
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="sec.cap.aws-service-broker-setup">
   <title>Setup</title>
   <procedure>
    <step>
     <para>
      Create the required DynamoDB table where the AWS service broker will
      store its data. This example creates a table named
      <literal>awssb</literal>:
     </para>
<screen>&prompt.user;aws dynamodb create-table \
		--attribute-definitions \
			AttributeName=id,AttributeType=S \
			AttributeName=userid,AttributeType=S \
			AttributeName=type,AttributeType=S \
		--key-schema \
			AttributeName=id,KeyType=HASH \
			AttributeName=userid,KeyType=RANGE \
		--global-secondary-indexes \
			'IndexName=type-userid-index,KeySchema=[{AttributeName=type,KeyType=HASH},{AttributeName=userid,KeyType=RANGE}],Projection={ProjectionType=INCLUDE,NonKeyAttributes=[id,userid,type,locked]},ProvisionedThroughput={ReadCapacityUnits=5,WriteCapacityUnits=5}' \
		--provisioned-throughput \
			ReadCapacityUnits=5,WriteCapacityUnits=5 \
		--region ${AWS_REGION} --table-name <replaceable>awssb</replaceable>
</screen>
    </step>
    <step>
     <para>
      Wait until the table has been created. When it is ready, the
      <literal>TableStatus</literal> will change to <literal>ACTIVE</literal>.
      Check the status using the <command>describe-table</command> command:
     </para>
<screen>aws dynamodb describe-table --table-name <replaceable>awssb</replaceable></screen>
     <para>
      (For more information about the <command>describe-table</command>
      command, see
      <link xlink:href="https://docs.aws.amazon.com/cli/latest/reference/dynamodb/describe-table.html"/>.)
     </para>
    </step>
    <step>
     <para>
      Set a name for the &kube; namespace you will install the service broker
      to. This name will also be used in the service broker URL:
     </para>
<screen>&prompt.user;BROKER_NAMESPACE=aws-sb</screen>
    </step>
    <step>
     <para>
      Create a server certificate for the service broker:
     </para>
     <substeps>
      <step>
       <para>
        Create and use a separate directory to avoid conflicts with other CA
        files:
       </para>
<screen>&prompt.user;mkdir /tmp/aws-service-broker-certificates &amp;&amp; cd $_</screen>
      </step>
      <step>
       <para>
        Get the CA certificate:
       </para>
<screen>kubectl get secret --namespace scf --output jsonpath='{.items[*].data.internal-ca-cert}' | base64 -di > ca.pem</screen>
      </step>
      <step>
       <para>
        Get the CA private key:
       </para>
<screen>kubectl get secret --namespace scf --output jsonpath='{.items[*].data.internal-ca-cert-key}' | base64 -di > ca.key</screen>
      </step>
      <step>
       <para>
	Create a signing request. Replace <literal>BROKER_NAMESPACE</literal> with the namespace assigned in Step 3:
       </para>
<screen>&prompt.user;openssl req -newkey rsa:4096 -keyout tls.key.encrypted -out tls.req -days 365 \
  -passout pass:<replaceable>1234</replaceable> \
  -subj '/CN=aws-servicebroker.'${BROKER_NAMESPACE} -batch \
  &lt;/dev/null
</screen>
      </step>
      <step>
       <para>
        Decrypt the generated broker private key:
       </para>
<screen>&prompt.user;openssl rsa -in tls.key.encrypted -passin pass:<replaceable>1234</replaceable> -out tls.key</screen>
      </step>
      <step>
       <para>
        Sign the request with the CA certificate:
       </para>
<screen>&prompt.user;openssl x509 -req -CA ca.pem -CAkey ca.key -CAcreateserial -in tls.req -out tls.pem</screen>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Install the AWS service broker as documented at
      <link xlink:href="https://github.com/awslabs/aws-servicebroker/blob/master/docs/getting-started-k8s.md"/>.
      Skip the installation of the Kubernetes Service Catalog. While installing
      the AWS Service Broker, make sure to update the &helm; chart version (the
      version as of this writing is <literal>1.0.0-beta.3</literal>). For the
      broker install, pass in a value indicating the Cluster Service Broker
      should not be installed (for example <command>--set
      deployClusterServiceBroker=false</command>). Ensure an account and role
      with adequate IAM rights is chosen (see
      <xref linkend="sec.cap.aws-service-broker-prereqs"/>:
     </para>
<screen>&prompt.user;helm install aws-sb/aws-servicebroker \
	     --name aws-servicebroker \
	     --namespace ${BROKER_NAMESPACE} \
	     --version 1.0.0-beta.3 \
	     --set aws.secretkey=$aws_access_key \
	     --set aws.accesskeyid=$aws_key_id \
	     --set deployClusterServiceBroker=false \
	     --set tls.cert="$(base64 -w0 tls.pem)" \
	     --set tls.key="$(base64 -w0 tls.key)" \
	     --set-string aws.targetaccountid=${AWS_TARGET_ACCOUNT_ID} \
	     --set aws.targetrolename=${AWS_TARGET_ROLE_NAME} \
	     --set aws.tablename=awssb \
	     --set aws.vpcid=$vpcid \
	     --set aws.region=$aws_region \
	     --set authenticate=false
</screen>
    </step>
    <step>
     <para>
      Log into your &cap; deployment. Select an organization and space to work
      with, creating them if needed:
     </para>
<screen>&prompt.user;cf api --skip-ssl-validation <replaceable>https://api.example.com</replaceable>
&prompt.user;cf login -u <replaceable>admin</replaceable> -p <replaceable>password</replaceable>
&prompt.user;cf create-org <replaceable>org</replaceable>
&prompt.user;cf create-space <replaceable>space</replaceable>
&prompt.user;cf target -o <replaceable>org</replaceable> -s <replaceable>space</replaceable>
</screen>
    </step>
    <step>
     <para>
      Create a service broker in <literal>scf</literal>. Note the name of the
      service broker should be the same as the one specified for the
      <literal>--name</literal> flag in the <command>helm install</command>
      step (for example <literal>aws-servicebroker</literal>. Note that the
      username and password parameters are only used as dummy values to pass to
      the <command>cf</command> command:
     </para>
<screen>&prompt.user;cf create-service-broker aws-servicebroker <replaceable>username</replaceable> <replaceable>password</replaceable>  https://aws-servicebroker.${BROKER_NAMESPACE}</screen>
    </step>
    <step>
     <para>
      Verify the service broker has been registered:
     </para>
<screen>&prompt.user;cf service-brokers</screen>
    </step>
    <step>
     <para>
      List the available service plans:
     </para>
<screen>&prompt.user;cf service-access</screen>
    </step>
    <step>
     <para>
      Enable access to a service. This example uses the <literal>-p</literal>
      to enable access to a specific service plan. See
      <link xlink:href="https://github.com/awslabs/aws-servicebroker/blob/master/templates/rdsmysql/template.yaml"/>
      for information about all available services and their associated plans:
     </para>
<screen>&prompt.user;cf enable-service-access rdsmysql -p custom</screen>
    </step>
    <step>
     <para>
      Create a service instance. As an example, a custom MySQL instance can be
      created as:
     </para>
<screen>&prompt.user;cf create-service rdsmysql custom mysql-instance-name -c '{
  "AccessCidr": "192.0.2.24/32",
  "BackupRetentionPeriod": 0,
  "MasterUsername": "master",
  "DBInstanceClass": "db.t2.micro",
  "PubliclyAccessible": "true",
  "region": "${AWS_REGION}",
  "StorageEncrypted": "false",
  "VpcId": "${AWS_VPC}",
  "target_account_id": "${AWS_TARGET_ACCOUNT_ID}",
  "target_role_name": "${AWS_TARGET_ROLE_NAME}"
}'
     </screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.cap.aws-service-broker-cleanup">
   <title>Cleanup</title>
   <para>
    When the AWS Service Broker and its services are no longer required,
    perform the following steps:
   </para>
   <procedure>
    <step>
     <para>
      Unbind any applications using any service instances then delete the
      service instance:
     </para>
<screen>&prompt.user;cf unbind-service my_app mysql-instance-name
&prompt.user;cf delete-service mysql-instance-name
</screen>
    </step>
    <step>
     <para>
      Delete the service broker in <literal>scf</literal>:
     </para>
<screen>&prompt.user;cf delete-service-broker aws-servicebroker</screen>
    </step>
    <step>
     <para>
      Delete the deployed &helm; chart and the namespace:
     </para>
<screen>&prompt.user;helm delete --purge aws-servicebroker
&prompt.user;kubectl delete namespace ${BROKER_NAMESPACE}
</screen>
    </step>
    <step>
     <para>
      The manually created DynamoDB table will need to be deleted as well:
     </para>
<screen>&prompt.user;aws dynamodb delete-table --table-name awssb --region ${AWS_REGION}</screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
</chapter>
