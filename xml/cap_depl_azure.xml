<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha.cap.depl-azure"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Preparing Microsoft Azure for &scf;</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 
  <para>
   Starting with version 1.1, &scf; supports deployment on Microsoft Azure 
   Kubernetes Service (AKS). This chapter describes how to prepare AKS for 
   deploying &scf; on an un-managed &kube; service. AKS provides &kube;, and
   then you will deploy &scf; on AKS.
 </para>
 
 <sect1 xml:id="sec.cap.install-az">
     <title>Prequisites</title>

<para>
     The first step is to install <command>az</command>, the Azure command-line
     client, on your remote administration machine. See 
     <link xlink:href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest">Install Azure CLI 2.0</link> 
     for instructions.
 </para>
 <para>
     See the 
     <link xlink:href="https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest">Azure CLI 2.0 Reference</link> 
     for a complete <command>az</command> command reference.
 </para>

 <para>
     You also need the <command>curl</command>, <command>sed</command>, and 
     <command>jq</command> commands, and the name of the SSH key attached to
     your Azure account.
 </para>
 
 <para>
     Log in to your Azure Account:
 </para>
 
 <screen>
&prompt.user;az login
</screen>
 
<para>
     Your Azure user needs the User Access Administrator role. Check your
     assigned roles with the <command>az</command> command:
</para>
 
 <screen>
&prompt.user;az role assignment list --assignee <replaceable>login-name</replaceable>
[...]
"roleDefinitionName": "User Access Administrator",
 </screen>
</sect1>

<sect1 xml:id="sec.cap.setup-kubernetes">
    <title>Set up &kube;</title>

<para>
    You need your Azure subscription ID. Extract it with <command>az</command>:
</para>

<screen>
&prompt.user;az account show --query "{ subscription_id: id }"
{
  "subscription_id": "a900cdi2-5983-0376-s7je-d4jdmsif84ca"
}
</screen>

<para>
    Replace <varname>subscription-id</varname> in the next 
    command with your <varname>subscription-id</varname>. Then export it as
    an environment variable, echo the variable to verify that it contains 
    the correct value, then set it as the current subscription: 
</para>

<screen>
&prompt.user;export SUBSCRIPTION_ID=<replaceable>a900cdi2-5983-0376-s7je-d4jdmsif84ca</replaceable>

&prompt.user; echo $SUBSCRIPTION_ID
 a900cdi2-5983-0376-s7je-d4jdmsif84ca

&prompt.user;az account set --subscription $SUBSCRIPTION_ID
</screen>

<para>
    The next three commands create a service principal. First create a resource 
    group. The <replaceable>--name</replaceable> is whatever you want, and 
    replace <replaceable>--location</replaceable> with your Azure region. 
    <command>az account list-locations</command> lists the regions
    supported for your account.
</para>

<screen>
&prompt.user;az group create --name <replaceable>scf-resource-group</replaceable> --location <replaceable>westus</replaceable>

 {
  "id": "/subscriptions/a900cdi2-5983-0376-s7je-d4jdmsif84ca/resourceGroups/scf-resource-group",
  "location": "westus",
  "managedBy": null,
  "name": "scf-resource-group",
  "properties": {
    "provisioningState": "Succeeded"
  },
  "tags": null
 }
</screen>

<para>
    Then create the service principal and configure its access to Azure 
    resources:
</para>

<screen>
&prompt.user;az ad sp create-for-rbac --role Contributor \
 --scopes "/subscriptions/$SUBSCRIPTION_ID/resourceGroups/<replaceable>scf-resource-group</replaceable>"
 
 {
  "appId": "bf7l052h-5853-c724-d99a-cd31844434ae",
  "displayName": "azure-cli-2018-05-23-11-11-22",
  "name": "http://azure-cli-2018-05-23-11-11-22",
  "password": "e09330ae-4881-ab22-9487-9b3d138b2af1",
  "tenant": "abcd7654-c007-1o10-d5h33-7833stc44s44"
  }
</screen>
<para>
    Record the <varname>appId</varname> and <varname>password</varname>, as you
    need them to create a container service. The parameters in the following
    example command to create the container service are explained below.
</para>

<screen>
&prompt.user;az acs create \
   --name "<replaceable>scf-container-service</replaceable>" \
   --resource-group "<replaceable>scf-resource-group</replaceable>" \
   --orchestrator-type "Kubernetes" \
   --dns-prefix "<replaceable>scfdns</replaceable>" \
   --master-count "<replaceable>1</replaceable>" \
   --admin-username "<replaceable>scf-admin</replaceable>" \
   --agent-count "<replaceable>3</replaceable>" \
   --client-secret "<replaceable>e09330ae-4881-ab22-9487-9b3d138b2af1</replaceable>" \
   --ssh-key-value "<replaceable>~/.ssh/ida_rsa.pub</replaceable>" \
   --service-principal "<replaceable>bf7l052h-5853-c724-d99a-cd31844434ae</replaceable>" \
   --master-vm-size "Standard_D2_v2"
</screen>
 takes time up to 30 minutes
alracdnsmgmt.eastus.cloudapp.azure.com
<itemizedlist>
  <listitem>
    <para>
        Create a new <varname>--name</varname> for your new container service.
    </para>
</listitem>
  <listitem>
    <para>
        The name of the <varname>--resource-group</varname> you created above.
    </para>
</listitem>
<listitem>
    <para>
        The <varname>--orchestrator-type</varname> must be 
        <literal>Kubernetes</literal>.
    </para>
</listitem>
<listitem>
    <para>
        Create the <varname>--dns-prefix</varname> for your cluster.
    </para>
</listitem>
<listitem>
    <para>
        Set the number of &kube; masters with 
        <varname>--master-count</varname>.
    </para>
</listitem>
<listitem>
    <para>
        Create the <varname>--admin-username</varname> for your cluster.
    </para>
    </listitem>
<listitem>
    <para>
        Set the number of &kube; minions with <varname>--agent-count</varname>.
    </para>
</listitem>
<listitem>
    <para>
        <varname>--client-secret</varname> is the password you recorded when you
        created the service principal.
    </para>
</listitem>
<listitem>
    <para>
       <varname>--ssh-key-value</varname> is the public SSH key associated with
       your Azure account.
   </para>
</listitem>
<listitem>
    <para>       
        <varname>--service-principal</varname> is the <literal>appId</literal>
        from your service principal creation.
    </para>
 </listitem>
<listitem>
    <para>       
        <varname>--master-vm-size</varname> <literal>Standard_D2_v2</literal> is 
                the default, and currently only value.
    </para>
</listitem>      
</itemizedlist>

<para>
    Prepare the &kube; environment. If there is another running &kube;, 
    copy the old configuration to a different location to start with a new
    empty configuration:
</para>
<screen>
&prompt.user;mv ~/.kube/config ~/.kube/config.old    

&prompt.user;az acs kubernetes get-credentials --resource-group="scf-resource-group" \
 --name="scf-container-service"
</screen>
<para>
    If your SSH key is password-protected, first load it into ssh-agent:
</para>
<screen>
&prompt.user;ssh-add ~/.ssh/<replaceable>private_key_name</replaceable>
</screen>
<para>
    Verify that &kube; is running, and that the version is 1.6 or greater:
</para>
<screen>
&prompt.user;kubectl get pods --all-namespaces
</screen>

<para>
    Enable cgroup swap accounting by running the following commands. This will 
    reboot some of the machines, which will take some time.
</para>
<screen>
&prompt.user;sudo zypper in -y jq sed

&prompt.user;az vm list -g "scf-resource-group" | jq '.[] | select (.tags.poolName | contains("agent")) | .name' | \
  xargs -i{} az vm run-command invoke \
  --resource-group "scf-resource-group" \
  --command-id RunShellScript \
  --scripts "sudo sed -i 's/GRUB_CMDLINE_LINUX_DEFAULT=\"console=tty1 console=ttyS0 earlyprintk=ttyS0 rootdelay=300\"/GRUB_CMDLINE_LINUX_DEFAULT=\"console=tty1 console=ttyS0 earlyprintk=ttyS0 rootdelay=300 swapaccount=1\"/g' \
  /etc/default/grub.d/50-cloudimg-settings.cfg" --name {}

&prompt.user;az vm list -g "scf-resource-group" | jq '.[] | select (.tags.poolName | contains("agent")) | .name' | \
  xargs -i{} az vm run-command invoke \
  --resource-group "scf-resource-group" \
  --command-id RunShellScript \
  --scripts "sudo update-grub" --name {}

&prompt.user;az vm list -g "scf-resource-group" | jq '.[] | select (.tags.poolName | contains("agent")) | .name' | \
  xargs -i{} az vm restart --no-wait \
  --resource-group "scf-resource-group" \
  --name {}
</screen>
<para>
    Create a new public IP address, which is needed for the &cap; deployment.
</para>
<screen>
&prompt.user;az network public-ip create --resource-group scf-resource-group \
 --name scf-public-ip --allocation-method Static
</screen>
<para>
    Extract the name of one of the &kube;' agent's network interface and write
    it down:
</para>
<screen>
&prompt.user;az network nic list --resource-group scf-resource-group | grep name | grep agent | grep 0
</screen>
<para>
    Replace <replaceable>nic-name</replaceable> in the following command 
    with the public IP address created in the previous command.
    Record the private IP address to use in the &cap; deployment.
</para>
<screen>
&prompt.user;az network nic ip-config update --resource-group scf-resource-group \
 --nic-name <replaceable>nic-name</replaceable> --name ipconfig1 \
 --public-ip-address scf-public-ip  
</screen>
<para>
    Extract the security group name of the master network security group and 
    write it down:
</para>
<screen>
&prompt.user;az network nsg list --resource-group=scf-resource-group | jq -r '.[] | .name' | grep master    
</screen>
<para>
    Create the required security groups, and replace 
    <replaceable>security-group</replaceable> with the name from the previous 
    command:
</para>
<screen>
&prompt.user;export NSG_NAME=<replaceable>security-group</replaceable>

&prompt.user;az network nsg rule create --resource-group scf-resource-group \
 --priority 200 --nsg-name $NSG_NAME --name scf-80 --direction Inbound \
 --destination-port-ranges 80 --access Allow

&prompt.user;az network nsg rule create --resource-group scf-resource-group \
 --priority 201 --nsg-name $NSG_NAME --name scf-443 --direction Inbound \
 --destination-port-ranges 443 --access Allow

&prompt.user;az network nsg rule create --resource-group scf-resource-group \
 --priority 202 --nsg-name $NSG_NAME --name scf-4443 --direction Inbound 
 --destination-port-ranges 4443 --access Allow

&prompt.user;az network nsg rule create --resource-group scf-resource-group \
 --priority 203 --nsg-name $NSG_NAME --name scf-2222 --direction Inbound \
 --destination-port-ranges 2222 --access Allow

&prompt.user;az network nsg rule create --resource-group scf-resource-group 
 --priority 204 --nsg-name $NSG_NAME --name scf-2793 --direction Inbound \
 --destination-port-ranges 2793 --access Allow
</screen>
</sect1>

<sect1 xml:id="sec.cap.deploy-cap">
    <title>Deploying &productname;</title>
    <para>
        When you deploy &productname; you will need the public and private IP
        addresses you recorded in the previous steps. Once the &kube; environment 
        is prepared, proceed with deployment of &productname; as described in 
        the 
        <link xlink:href="https://www.suse.com/documentation/cloud-application-platform-1/index.html">SUSE Cloud Application Platform 1 Deployment Guide</link>.
    </para>
    <note>
        <title>Special Configuration for Azure</title>
        <para>
           When deploying to Azure, you must set the Garden rootfs driver to 
           <varname>overlay-xfs</varname> (the default is btrfs). Enter the 
           following key in the your
           <filename>scf-config-values.yaml</filename>:
       </para>
       <screen>
env:
  GARDEN_ROOTFS_DRIVER: "overlay-xfs"
</screen>
</note>
    
 </sect1>
</chapter>
