<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha-cap-depl-caasp"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Deploying &productname; on &caasp;</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <important>
  &readmefirst;
 </important>

 <para>
  &productname; supports deployment on &caasp;. &caasp; is an enterprise-class
  container management solution that enables IT and DevOps professionals to more
  easily deploy, manage, and scale container-based applications and services. It
  includes &kube; to automate lifecycle management of modern applications, and
  surrounding technologies that enrich Kubernetes and make the platform itself
  easy to operate. As a result, enterprises that use &caasp; can reduce
  application delivery cycle times and improve business agility. This chapter
  describes the steps to prepare a &productname; deployment on &caasp;. See
  <link xlink:href="https://documentation.suse.com/suse-caasp/4.1/"/>              
  for more information on &caasp;.
 </para>

 <sect1 xml:id="sec-cap-prereqs-caasp">
  <title>Prerequisites</title>

  <para>
   The following are required to deploy and use &productname; on &caasp;:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Access to one of the following platforms to deploy &caasp;:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       &suse; OpenStack Cloud 8
      </para>
     </listitem>
     <listitem>
      <para>
       &vmware; VMware ESXi 6.7.0.20000
      </para>
     </listitem>
     <listitem>
      <para>
       Bare Metal x86_64
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     A management workstation, which is used to deploy and control a &caasp;
     cluster, that is capable of running <literal>skuba</literal> (see
     <link xlink:href="https://github.com/SUSE/skuba"/> for installation
     instructions). The management workstation can be a regular
     desktop workstation or laptop running &sle; 15 SP1 or later.
    </para>
   </listitem>

   <!-- listitems: Install steps and links -->
   &cfcli-prereq;
   &kubectl-prereq;
   &jq-prereq;
   &curl-prereq;
   &sed-prereq;
  </itemizedlist>

  &min-deploy-note;
 </sect1>

 <sect1 xml:id="sec-cap-create-caasp-cluster">
  <title>Creating a &caasp; Cluster</title>

  <para>
   When creating a &caasp; cluster, take note of the following general
   guidelines to ensure there are sufficient resources available to run a
   &productname; deployment:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     Minimum 2.3 GHz processor
    </para>
   </listitem>
   <listitem>
    <para>
     2 vCPU per physical core
    </para>
   </listitem>
   <listitem>
    <para>
     4 GB RAM per vCPU
    </para>
   </listitem>
   <listitem>
    <para>
     Worker nodes need a minimum of 4 vCPU and 16 GB RAM
    </para>
   </listitem>
  </itemizedlist>
  <para>
   As a minimum, a &productname; deployment with a basic workload will require:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     1 master node
    </para>
    <itemizedlist>
     <listitem>
      <para>
       vCPU: 2
      </para>
     </listitem>
     <listitem>
      <para>
       RAM: 8 GB
      </para>
     </listitem>
     <listitem>
      <para>
       Storage: 60 GB (SSD)
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     2 worker nodes. Each node configured with:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       (v)CPU: 4
      </para>
     </listitem>
     <listitem>
      <para>
       RAM: 16 GB
      </para>
     </listitem>
     <listitem>
      <para>
       Storage: 100 GB
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Persistent storage: 40 GB
    </para>
   </listitem>
  </itemizedlist>

  <para>
   For steps to deploy a &caasp; cluster, refer to the &caasp; Deployment Guide
   at <link xlink:href="https://documentation.suse.com/suse-caasp/4.1/single-html/caasp-deployment/"/>
  </para>
  <para>
   When proceeding through the instructions, take note of the following to
   ensure the &caasp; cluster is suitable for a deployment of &productname;:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     At the cluster initialization step, <emphasis role="bold">do not</emphasis>
     use the <literal>--strict-capability-defaults</literal> option when running
    </para> 
<screen>&prompt.user;skuba cluster init</screen>
    <para>
     This ensures the presence of extra CRI-O capabilities compatible with
     &docker; containers. For more details refer to the
     <link xlink:href="https://documentation.suse.com/suse-caasp/4.1/single-html/caasp-deployment/#_transitioning_from_docker_to_cri_o"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Swapaccounting is enabled on all worker nodes. For each node:
    </para>
    <procedure>
     <step>
      <para>
       SSH into the node.
      </para>
      <substeps>
       <step>
        <para>
	 If the <command>ssh-agent</command> is running, run:
	</para>
<screen>&prompt.user;ssh <replaceable>sles</replaceable>@&lt;NODE_IP_ADDRESS></screen>
       </step>
       <step>
        <para>
       	 Without the <command>ssh-agent</command> running, run:
	</para>
<screen>&prompt.user;ssh <replaceable>sles</replaceable>@&lt;NODE_IP_ADDRESS> -i &lt;PATH_TO_YOUR_SSH_PRIVATE_KEY></screen>
       </step>
      </substeps>
     </step>
     <step>
      <para>
       Enable swapaccounting on the node.
      </para>
<screen>&prompt.user;grep "swapaccount=1" /etc/default/grub || sudo sed -i -r 's|^(GRUB_CMDLINE_LINUX_DEFAULT=)\"(.*.)\"|\1\"\2 swapaccount=1 \"|' /etc/default/grub
&prompt.user;sudo grub2-mkconfig -o /boot/grub2/grub.cfg
&prompt.user;sudo systemctl reboot
</screen>
     </step>
    </procedure>
   </listitem>
  </itemizedlist>
 </sect1>

 <sect1 xml:id="sec-cap-caasp-tiller">
  <title>Installing &helm; Client and &tiller;</title>

  <para>
   &helm; is a &kube; package manager. It consists of a client and server
   component, both of which are required in order to install and manage &cap;.
  </para>
  <para>
   The &helm; client, <literal>helm</literal>, can be installed on your
   management workstation, which is part of the &caasp; package repository, by
   running
  </para>
<screen>&prompt.user;sudo zypper install helm</screen>
  <para>
   Alternatively, refer to the upstream documentation at
   <link xlink:href="https://docs.helm.sh/using_helm/#installing-helm"/>. &cap;
   is compatible with both &helm; 2 and &helm; 3. Examples in this guide are
   based on &helm; 2. To use &helm; 3, refer to the &helm; documentation at
   <link xlink:href="https://helm.sh/docs/"/>.     
  </para>
  <para>
   &tiller;, the &helm; server component, needs to be installed on your &kube;
   cluster. To install, follow the instructions at
   <link xlink:href="https://documentation.suse.com/suse-caasp/4.1/single-html/caasp-admin/#_installing_tiller"/>. Alternatively, refer to the upstream documentation at
   <link xlink:href="https://helm.sh/docs/using_helm/#installing-tiller"/> to
   install &tiller; with a service account and ensure your installation is
   appropriately secured according to your requirements as described in
   <link xlink:href="https://helm.sh/docs/using_helm/#securing-your-helm-installation"/>.
  </para>
 </sect1>

 <sect1 xml:id="sec-cap-caasp-storage">
  <title>Storage Class</title>

  <para>
   &productname; requires a persistent storage class to store persistent data
   inside a persistent volume (PV). When a PV is provisioned, the storage class'
   provisioner determines the volume plugin used. Create a storage class using a
   provisioner (see
   <link xlink:href="https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner"/>)
   that fits your storage strategy. Examples of provisioners include:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     &ses; (see
     <link xlink:href="https://documentation.suse.com/suse-caasp/4.1/single-html/caasp-admin/#_RBD-dynamic-persistent-volumes"/>)
    </para>
    <para>
     If you are using &ses; you must copy the Ceph admin secret to the
     <literal>uaa</literal> and <literal>scf</literal> namespaces used by
     &productname;:
    </para>
<screen>&prompt.user;kubectl get secret ceph-secret-admin --output json --namespace default | \
sed 's/"namespace": "default"/"namespace": "uaa"/' | kubectl create --filename -
&prompt.user;kubectl get secret ceph-secret-admin --output json --namespace default | \
sed's/"namespace": "default"/"namespace": "scf"/' | kubectl create --filename -
</screen>
   </listitem>
   <listitem>
    <para>
     Network File System (see
     <link xlink:href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs"/>
    </para>
   </listitem>
  </itemizedlist>
  <para>
   By default &productname; assumes your storage class is named
   <literal>persistent</literal>. Examples in this guide follow this assumption.
   If your storage class uses a different name, adjust the
   <literal>kube.storage_class.persistent</literal> value in your configuration
   file.
  </para>
 </sect1>

 <sect1 xml:id="sec-cap-caasp-config">
  <title>Deployment Configuration</title>

  <para>
   &productname; is configured using &helm; values (see
   <link xlink:href="https://helm.sh/docs/chart_template_guide/values_files/"/>
   . &helm; values can be set as either command line parameters or using a
   <filename>values.yaml</filename> file. The following
   <filename>values.yaml</filename> file, called
   <filename>scf-config-values.yaml</filename> in this guide, provides an
   example of a &productname; configuration.
  </para>
  <para> 
   Ensure <literal>DOMAIN</literal> maps to the load balancer configured for
   your &caasp; cluster (see
   <link xlink:href="https://documentation.suse.com/suse-caasp/4.1/single-html/caasp-deployment/#loadbalancer"/>). 
  </para>

  &supported-domains;

<screen>
### example deployment configuration file
### scf-config-values.yaml

env:
  DOMAIN: <replaceable>example.com</replaceable>
  # the UAA prefix is required
  UAA_HOST: uaa.<replaceable>example.com</replaceable>
  UAA_PORT: 2793
  GARDEN_ROOTFS_DRIVER: "btrfs"

kube:
  external_ips: ["&lt;CAASP_MASTER_NODE_EXTERNAL_IP>","&lt;CAASP_MASTER_NODE_INTERNAL_IP>"]

  storage_class:
    persistent: "persistent"
    shared: "shared"

  registry:
    hostname: "registry.suse.com"
    username: ""
    password: ""
  organization: "cap"

secrets:
  # Create a very strong password for user 'admin'
  CLUSTER_ADMIN_PASSWORD: <replaceable>password</replaceable>

  # Create a very strong password, and protect it because it
  # provides root access to everything
  UAA_ADMIN_CLIENT_SECRET: <replaceable>password</replaceable>
</screen>

  <!-- Explains usage of some Helm values used in the example/minimal values.yaml-->
  &config-value-usage;                                                          
                                                                                
  <!-- Reiterates importance of this password -->                               
  &protect-uaa-admin-secret;
 </sect1>

 <sect1 xml:id="sec-cap-addrepo-caasp">
  <title>Add the &kube; Charts Repository</title>

  <para>
   Download the &suse; &kube; charts repository with &helm;:
  </para>

<screen>&prompt.user;helm repo add <replaceable>suse</replaceable> https://kubernetes-charts.suse.com/</screen>

  <para>
   You may replace the example <replaceable>suse</replaceable> name with any
   name. Verify with <command>helm</command>:
  </para>

<screen>&prompt.user;helm repo list
NAME       URL
stable     https://kubernetes-charts.storage.googleapis.com
local      http://127.0.0.1:8879/charts
suse       https://kubernetes-charts.suse.com/
</screen>

  <para>
   List your chart names, as you will need these for some operations:
  </para>

&helm-search-suse;
 </sect1>

 <sect1 xml:id="sec-cap-cap-on-caasp">
  <title>Deploying &productname;</title>

  <sect2 xml:id="sec-cap-caasp-deploy-uaa">
   <title>Deploy <literal>uaa</literal></title>

   &uaa-in-scf;

   <para>
    Use &helm; to deploy the <literal>uaa</literal> server:
   </para>
<screen>&prompt.user;kubectl create namespace <replaceable>uaa</replaceable>

&prompt.user;helm install <replaceable>susecf-uaa</replaceable> suse/uaa \
--namespace <replaceable>uaa</replaceable> \
--values <replaceable>scf-config-values.yaml</replaceable>
</screen>
   &uaa-deploy-complete;
   <para>
    Use <command>curl</command> to verify you are able to connect to the
    <literal>uaa</literal> OAuth server on the DNS name configured:
   </para>
<screen>&prompt.user;curl --insecure https://uaa.example.com:2793/.well-known/openid-configuration</screen>
   <para>
    This should return a JSON object, as this abbreviated example shows:
   </para>
<screen>{"issuer":"https://uaa.example.com:2793/oauth/token",
"authorization_endpoint":"https://uaa.example.com:2793
/oauth/authorize","token_endpoint":"https://uaa.example.com:2793/oauth/token"
</screen>
  </sect2>

  <sect2 xml:id="sec-cap-caasp-deploy-scf">                                       
   <title>Deploy <literal>scf</literal></title>
   <para>
    Use &helm; to deploy <literal>scf</literal>:
   </para>

   &uaa-ca-cert-note;

<screen>&prompt.user;kubectl create namespace <replaceable>scf</replaceable>

&prompt.user;helm install <replaceable>susecf-scf</replaceable> suse/cf \
--namespace <replaceable>scf</replaceable> \
--values scf-config-values.yaml
</screen>
   &scf-deploy-complete; 

   <para>
    When the deployment completes, use the &cf; command line interface to log in
    to &suse; &cf; to deploy and manage your applications. (See
    <xref linkend="sec-cap-cf-cli"/>)
   </para>
  </sect2>
 </sect1>

 <sect1 xml:id="sec-cap-caasp-add-capacity">
  <title>Expanding Capacity of a &cap; Deployment on &susecaaspreg;</title>

  <para>
   If the current capacity of your &cap; deployment is insufficient for your
   workloads, you can expand the capacity using the procedure in this section.
  </para>

  <para>
   These instructions assume you have followed the procedure in
   <xref linkend="cha-cap-depl-caasp"/> and have a running &cap;
   deployment on &susecaaspreg;.
  </para>

  <procedure>
   <step>
    <para>
     Add additional nodes to your &susecaaspreg; cluster as described in
     <link xlink:href="https://documentation.suse.com/suse-caasp/4.1/html/caasp-admin/_cluster_management.html#adding_nodes"/>.
    </para>
   </step>
   <step>
    <para>
     Verify the new nodes are in a <literal>Ready</literal> state before proceeding.
    </para>
<screen>&prompt.user;kubectl get nodes</screen>
   </step>
   <step>
    <para>
     Add or update the following in your
     <filename>scf-config-values.yaml</filename> file to increase the number of
     <literal>diego-cell</literal> in your &cap; deployment. Replace the
     example value with the number required by your workflow.
    </para>
<screen>sizing:
  diego_cell:
    count: <replaceable>4</replaceable>
</screen>
   </step>
   <step>
    <para>
     Perform a <command>helm upgrade</command> to apply the change.
    </para>

    &uaa-ca-cert-note;

<screen>&prompt.user;helm upgrade susecf-scf suse/cf \
--values scf-config-values.yaml \
--version &latestscfchart;
</screen>
   </step>
   <step>
    <para>
     Monitor progress of the additional <literal>diego-cell</literal> pods:
    </para>
<screen>&prompt.user;watch --color 'kubectl get pods --namespace scf'</screen>
   </step>
  </procedure>
 </sect1>
</chapter>
